{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split values based on the two CSVs\n",
    "training_csv = pd.read_csv(\"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/train.csv\")\n",
    "testing_csv = pd.read_csv(\"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/test.csv\")\n",
    "\n",
    "#training_csv.to_csv('titanic_training.csv', index=False, encoding='utf-8')\n",
    "#testing_csv.to_csv('titanic_testing.csv', index=False, encoding='utf-8')\n",
    "\n",
    "data = training_csv\n",
    "target = data['Survived'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.2500</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.9250</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0500</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fare  Pclass  Age  Sex_female  Embarked_C  Embarked_Q  Embarked_S\n",
       "0   7.2500       3   22           0           0           0           1\n",
       "1  71.2833       1   38           1           1           0           0\n",
       "2   7.9250       3   26           1           0           0           1\n",
       "3  53.1000       1   35           1           0           0           1\n",
       "4   8.0500       3   35           0           0           0           1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split values into numerical and categorical features\n",
    "numerical_features = data[['Fare','Pclass','Age']]\n",
    "# Need to handle values where Age is missing\n",
    "features = pd.concat([data[['Fare', 'Pclass', 'Age']],\n",
    "                           pd.get_dummies(data['Sex'], prefix='Sex'),\n",
    "                           pd.get_dummies(data['Embarked'], prefix='Embarked')],\n",
    "                          axis=1)\n",
    "features = features.drop('Sex_male', 1)\n",
    "features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will try to loop through the different classes and sex to apply the median age\n",
    "for sex in xrange(0,2):\n",
    "    for cabin_class in xrange(0,4):\n",
    "        median_age_group = features[(features.Pclass == cabin_class) & (features.Sex_female == sex)].dropna().median()\n",
    "        features[(features.Pclass == cabin_class) \n",
    "                 & (features.Sex_female == sex)] = features[(features.Pclass == cabin_class) \n",
    "                                                                     & (features.Sex_female == sex)\n",
    "                                                                    ].fillna(median_age_group)\n",
    "# adding validation for if the person is a child\n",
    "features['child'] = (features.Age <= 18)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>child</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.2500</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.9250</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0500</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fare  Pclass  Age  Sex_female  Embarked_C  Embarked_Q  Embarked_S  child\n",
       "0   7.2500       3   22           0           0           0           1      0\n",
       "1  71.2833       1   38           1           1           0           0      0\n",
       "2   7.9250       3   26           1           0           0           1      0\n",
       "3  53.1000       1   35           1           0           0           1      0\n",
       "4   8.0500       3   35           0           0           0           1      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.25      ,   3.        ,  22.        , ...,   0.        ,\n",
       "          1.        ,   0.        ],\n",
       "       [ 71.28330231,   1.        ,  38.        , ...,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  7.92500019,   3.        ,  26.        , ...,   0.        ,\n",
       "          1.        ,   0.        ],\n",
       "       ..., \n",
       "       [ 23.45000076,   3.        ,  21.5       , ...,   0.        ,\n",
       "          1.        ,   0.        ],\n",
       "       [ 30.        ,   1.        ,  26.        , ...,   0.        ,\n",
       "          0.        ,   0.        ],\n",
       "       [  7.75      ,   3.        ,  32.        , ...,   1.        ,\n",
       "          0.        ,   0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.asarray(features.values, 'float32')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -7.30, time = 0.06s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -5.73, time = 0.04s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -4.63, time = 0.03s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -4.79, time = 0.03s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -4.77, time = 0.04s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -4.48, time = 0.05s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -4.86, time = 0.07s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -4.19, time = 0.06s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -4.22, time = 0.05s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -4.17, time = 0.07s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -4.14, time = 0.07s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -4.22, time = 0.04s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -3.84, time = 0.04s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -4.09, time = 0.06s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -4.11, time = 0.05s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -3.89, time = 0.06s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -3.87, time = 0.05s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -3.98, time = 0.07s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -3.81, time = 0.04s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -3.83, time = 0.06s\n",
      "\n",
      "Logistic regression using RBM features:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.84      0.83       110\n",
      "          1       0.73      0.71      0.72        69\n",
      "\n",
      "avg / total       0.79      0.79      0.79       179\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def nudge_dataset(X, Y):\n",
    "    \"\"\"\n",
    "    This produces a dataset 5 times bigger than the original one,\n",
    "    by moving the 8x8 images in X around by 1px to left, right, down, up\n",
    "    \"\"\"\n",
    "    direction_vectors = [\n",
    "        [[0, 1, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 0, 0]],\n",
    "\n",
    "        [[0, 0, 0],\n",
    "         [1, 0, 0],\n",
    "         [0, 0, 0]],\n",
    "\n",
    "        [[0, 0, 0],\n",
    "         [0, 0, 1],\n",
    "         [0, 0, 0]],\n",
    "\n",
    "        [[0, 0, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 1, 0]]]\n",
    "\n",
    "    shift = lambda x, w: convolve(x.reshape((8, 8)), mode='constant',\n",
    "                                  weights=w).ravel()\n",
    "    X = np.concatenate([X] +\n",
    "                       [np.apply_along_axis(shift, 1, X, vector)\n",
    "                        for vector in direction_vectors])\n",
    "    Y = np.concatenate([Y for _ in range(5)], axis=0)\n",
    "    return X, Y\n",
    "\n",
    "# Load Data\n",
    "#digits = datasets.load_digits()\n",
    "X = np.asarray(features.values, 'float32')\n",
    "Y = target\n",
    "#X, Y = nudge_dataset(X, target)\n",
    "X = (X - np.min(X, 0)) / (np.max(X, 0) + 0.0001)  # 0-1 scaling\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Models we will use\n",
    "logistic = linear_model.LogisticRegression()\n",
    "rbm = BernoulliRBM(random_state=0, verbose=True)\n",
    "\n",
    "classifier = Pipeline(steps=[('rbm', rbm), ('logistic', logistic)])\n",
    "\n",
    "###############################################################################\n",
    "# Training\n",
    "\n",
    "# Hyper-parameters. These were set by cross-validation,\n",
    "# using a GridSearchCV. Here we are not performing cross-validation to\n",
    "# save time.\n",
    "rbm.learning_rate = 0.06\n",
    "rbm.n_iter = 20\n",
    "# More components tend to give better prediction performance, but larger\n",
    "# fitting time\n",
    "rbm.n_components = 100\n",
    "logistic.C = 6000.0\n",
    "\n",
    "# Training RBM-Logistic Pipeline\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Training Logistic regression\n",
    "logistic_classifier = linear_model.LogisticRegression(C=100.0)\n",
    "logistic_classifier.fit(X_train, Y_train)\n",
    "\n",
    "###############################################################################\n",
    "# Evaluation\n",
    "\n",
    "print()\n",
    "print(\"Logistic regression using RBM features:\\n%s\\n\" % (\n",
    "    metrics.classification_report(\n",
    "        Y_test,\n",
    "        classifier.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -25.39, time = 0.22s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -23.77, time = 0.42s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -22.94, time = 0.36s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -21.91, time = 0.34s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -21.69, time = 0.42s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -21.06, time = 0.47s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -20.89, time = 0.48s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -20.64, time = 0.41s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -20.36, time = 0.34s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -20.09, time = 0.33s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -20.08, time = 0.35s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -19.82, time = 0.38s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -19.64, time = 0.58s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -19.61, time = 0.31s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -19.57, time = 0.51s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -19.41, time = 0.30s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -19.30, time = 0.31s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -19.25, time = 0.31s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -19.27, time = 0.55s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -19.01, time = 0.37s\n",
      "\n",
      "Logistic regression using RBM features:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99       174\n",
      "          1       0.92      0.95      0.93       184\n",
      "          2       0.95      0.98      0.97       166\n",
      "          3       0.97      0.91      0.94       194\n",
      "          4       0.97      0.95      0.96       186\n",
      "          5       0.93      0.93      0.93       181\n",
      "          6       0.98      0.97      0.97       207\n",
      "          7       0.95      1.00      0.97       154\n",
      "          8       0.90      0.88      0.89       182\n",
      "          9       0.91      0.93      0.92       169\n",
      "\n",
      "avg / total       0.95      0.95      0.95      1797\n",
      "\n",
      "\n",
      "Logistic regression using raw pixel features:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.94      0.89       174\n",
      "          1       0.57      0.55      0.56       184\n",
      "          2       0.72      0.85      0.78       166\n",
      "          3       0.76      0.74      0.75       194\n",
      "          4       0.85      0.82      0.84       186\n",
      "          5       0.74      0.75      0.75       181\n",
      "          6       0.93      0.88      0.91       207\n",
      "          7       0.86      0.90      0.88       154\n",
      "          8       0.68      0.55      0.61       182\n",
      "          9       0.71      0.74      0.72       169\n",
      "\n",
      "avg / total       0.77      0.77      0.77      1797\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "# Authors: Yann N. Dauphin, Vlad Niculae, Gabriel Synnaeve\n",
    "# License: BSD\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.ndimage import convolve\n",
    "from sklearn import linear_model, datasets, metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Setting up\n",
    "\n",
    "def nudge_dataset(X, Y):\n",
    "    \"\"\"\n",
    "    This produces a dataset 5 times bigger than the original one,\n",
    "    by moving the 8x8 images in X around by 1px to left, right, down, up\n",
    "    \"\"\"\n",
    "    direction_vectors = [\n",
    "        [[0, 1, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 0, 0]],\n",
    "\n",
    "        [[0, 0, 0],\n",
    "         [1, 0, 0],\n",
    "         [0, 0, 0]],\n",
    "\n",
    "        [[0, 0, 0],\n",
    "         [0, 0, 1],\n",
    "         [0, 0, 0]],\n",
    "\n",
    "        [[0, 0, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 1, 0]]]\n",
    "\n",
    "    shift = lambda x, w: convolve(x.reshape((8, 8)), mode='constant',\n",
    "                                  weights=w).ravel()\n",
    "    X = np.concatenate([X] +\n",
    "                       [np.apply_along_axis(shift, 1, X, vector)\n",
    "                        for vector in direction_vectors])\n",
    "    Y = np.concatenate([Y for _ in range(5)], axis=0)\n",
    "    return X, Y\n",
    "\n",
    "# Load Data\n",
    "digits = datasets.load_digits()\n",
    "X = np.asarray(digits.data, 'float32')\n",
    "X, Y = nudge_dataset(X, digits.target)\n",
    "X = (X - np.min(X, 0)) / (np.max(X, 0) + 0.0001)  # 0-1 scaling\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Models we will use\n",
    "logistic = linear_model.LogisticRegression()\n",
    "rbm = BernoulliRBM(random_state=0, verbose=True)\n",
    "\n",
    "classifier = Pipeline(steps=[('rbm', rbm), ('logistic', logistic)])\n",
    "\n",
    "###############################################################################\n",
    "# Training\n",
    "\n",
    "# Hyper-parameters. These were set by cross-validation,\n",
    "# using a GridSearchCV. Here we are not performing cross-validation to\n",
    "# save time.\n",
    "rbm.learning_rate = 0.06\n",
    "rbm.n_iter = 20\n",
    "# More components tend to give better prediction performance, but larger\n",
    "# fitting time\n",
    "rbm.n_components = 100\n",
    "logistic.C = 6000.0\n",
    "\n",
    "# Training RBM-Logistic Pipeline\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Training Logistic regression\n",
    "logistic_classifier = linear_model.LogisticRegression(C=100.0)\n",
    "logistic_classifier.fit(X_train, Y_train)\n",
    "\n",
    "###############################################################################\n",
    "# Evaluation\n",
    "\n",
    "print()\n",
    "print(\"Logistic regression using RBM features:\\n%s\\n\" % (\n",
    "    metrics.classification_report(\n",
    "        Y_test,\n",
    "        classifier.predict(X_test))))\n",
    "\n",
    "print(\"Logistic regression using raw pixel features:\\n%s\\n\" % (\n",
    "    metrics.classification_report(\n",
    "        Y_test,\n",
    "        logistic_classifier.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
